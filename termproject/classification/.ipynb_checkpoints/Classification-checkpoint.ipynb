{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- missing data before removal :  45211\n",
      "education    1857\n",
      "default         0\n",
      "balance         0\n",
      "housing         0\n",
      "loan            0\n",
      "dtype: int64\n",
      "- missing data after removal :  43354\n",
      "education    0\n",
      "default      0\n",
      "balance      0\n",
      "housing      0\n",
      "loan         0\n",
      "dtype: int64\n",
      "    education default  balance housing loan\n",
      "0    tertiary      no   2143.0     yes   no\n",
      "1  compulsory      no     29.0     yes   no\n",
      "2  compulsory      no      2.0     yes  yes\n",
      "3    tertiary      no    231.0     yes   no\n",
      "4    tertiary      no    447.0     yes  yes\n",
      "5    tertiary     yes      2.0     yes   no\n",
      "6  compulsory      no    121.0     yes   no\n",
      "7  compulsory      no    593.0     yes   no\n",
      "8  compulsory      no    270.0     yes   no\n",
      "9  compulsory      no    390.0     yes   no\n",
      "- data before removing redundancy :  43354\n",
      "- data after removing redundancy :  16883\n",
      "       education  default  balance  housing  loan\n",
      "0              1        0   2143.0        1     0\n",
      "1              0        0     29.0        1     0\n",
      "2              0        0      2.0        1     1\n",
      "3              1        0    231.0        1     0\n",
      "4              1        0    447.0        1     1\n",
      "5              1        1      2.0        1     0\n",
      "6              0        0    121.0        1     0\n",
      "7              0        0    593.0        1     0\n",
      "8              0        0    270.0        1     0\n",
      "9              0        0    390.0        1     0\n",
      "10             0        0      6.0        1     0\n",
      "11             0        0    162.0        1     0\n",
      "12             0        0    229.0        1     0\n",
      "13             0        0     52.0        1     0\n",
      "14             0        0     60.0        1     0\n",
      "15             0        0      0.0        1     0\n",
      "16             0        0    723.0        1     1\n",
      "17             1        0    779.0        1     0\n",
      "18             0        0     23.0        1     1\n",
      "19             0        0     50.0        1     0\n",
      "20             0        0      0.0        1     1\n",
      "21             0        0   -372.0        1     0\n",
      "22             1        0    255.0        1     0\n",
      "23             0        0    113.0        1     1\n",
      "24             0        0   -246.0        1     0\n",
      "25             0        0    265.0        1     1\n",
      "26             0        0    839.0        0     1\n",
      "27             1        0    378.0        1     0\n",
      "28             0        0     39.0        1     1\n",
      "30             1        0  10635.0        1     0\n",
      "...          ...      ...      ...      ...   ...\n",
      "43068          0        0   4416.0        0     0\n",
      "43070          0        0   1934.0        0     0\n",
      "43073          0        0   3311.0        0     0\n",
      "43075          1        0    318.0        1     1\n",
      "43076          1        0   1333.0        0     0\n",
      "43089          1        0   1278.0        0     0\n",
      "43090          1        0   1011.0        0     0\n",
      "43093          1        0   3466.0        0     0\n",
      "43101          0        0   7038.0        0     0\n",
      "43147          1        0   2916.0        0     0\n",
      "43153          1        0   1650.0        1     0\n",
      "43172          1        0   9710.0        0     0\n",
      "43178          0        0    471.0        0     0\n",
      "43184          1        0    319.0        0     0\n",
      "43199          1        0    922.0        0     0\n",
      "43209          1        0   2450.0        0     1\n",
      "43220          0        0   2400.0        0     0\n",
      "43224          0        0     50.0        0     1\n",
      "43257          1        0    844.0        1     1\n",
      "43258          1        0   8205.0        1     0\n",
      "43266          0        0  14204.0        0     0\n",
      "43268          0        0   1547.0        0     0\n",
      "43273          1        0    858.0        0     0\n",
      "43275          0        0  16353.0        0     0\n",
      "43282          0        0   1294.0        0     0\n",
      "43298          1        0   2059.0        0     1\n",
      "43301          1        0   3556.0        0     0\n",
      "43314          0        0    245.0        0     0\n",
      "43341          1        0   1428.0        0     0\n",
      "43349          1        0    825.0        0     0\n",
      "\n",
      "[16883 rows x 5 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "131\n",
      "- data before removing outlier :  16883\n",
      "- data after removing outlier :  16737\n",
      "[[0.         0.06715397 1.         0.        ]\n",
      " [0.         0.02197145 1.         0.        ]\n",
      " [0.         0.02139437 1.         1.        ]\n",
      " ...\n",
      " [0.         0.02658801 0.         0.        ]\n",
      " [0.         0.05187227 0.         0.        ]\n",
      " [0.         0.03898435 0.         0.        ]]\n",
      "[[ 0.11359247 -0.86773116  0.61873169 -0.33699793]\n",
      " [-0.2557798  -0.83861465  0.54394993 -0.7588224 ]\n",
      " [-1.62720765 -0.9582426  -0.72825631  0.64964184]\n",
      " ...\n",
      " [ 0.31476645  0.83568003 -0.38500895 -0.90045928]\n",
      " [ 0.52146815  0.81938635 -0.34316088 -0.66440519]\n",
      " [ 0.41610794  0.82769158 -0.36449172 -0.78472693]]\n",
      "DecisionTree =  gini\n",
      "[0.46567164 0.62328358 0.61910448 0.62126643 0.62223551 0.62283323\n",
      " 0.62223551 0.62044232 0.62223551 0.61984459]\n",
      "cv_scores mean:0.605915278790753\n",
      "\n",
      "DecisionTree =  entropy\n",
      "[0.46567164 0.62208955 0.61910448 0.62126643 0.62223551 0.62283323\n",
      " 0.62223551 0.62044232 0.62223551 0.61984459]\n",
      "cv_scores mean:0.6057958758056783\n",
      "\n",
      "Logistic =  solver :   liblinear  / max_iter :  50\n",
      "[0.62149254 0.62149254 0.62089552 0.61887694 0.62044232 0.62343096\n",
      " 0.62522415 0.62402869 0.6180514  0.61685595]\n",
      "cv_scores mean:0.6210791011275859\n",
      "\n",
      "Logistic =  solver :   liblinear  / max_iter :  100\n",
      "[0.62149254 0.62149254 0.62089552 0.61887694 0.62044232 0.62343096\n",
      " 0.62522415 0.62402869 0.6180514  0.61685595]\n",
      "cv_scores mean:0.6210791011275859\n",
      "\n",
      "Logistic =  solver :   liblinear  / max_iter :  200\n",
      "[0.62149254 0.62149254 0.62089552 0.61887694 0.62044232 0.62343096\n",
      " 0.62522415 0.62402869 0.6180514  0.61685595]\n",
      "cv_scores mean:0.6210791011275859\n",
      "\n",
      "Logistic =  solver :   lbfgs  / max_iter :  50\n",
      "[0.62149254 0.62149254 0.62089552 0.61887694 0.62044232 0.62343096\n",
      " 0.62522415 0.62402869 0.6180514  0.61685595]\n",
      "cv_scores mean:0.6210791011275859\n",
      "\n",
      "Logistic =  solver :   lbfgs  / max_iter :  100\n",
      "[0.62149254 0.62149254 0.62089552 0.61887694 0.62044232 0.62343096\n",
      " 0.62522415 0.62402869 0.6180514  0.61685595]\n",
      "cv_scores mean:0.6210791011275859\n",
      "\n",
      "Logistic =  solver :   lbfgs  / max_iter :  200\n",
      "[0.62149254 0.62149254 0.62089552 0.61887694 0.62044232 0.62343096\n",
      " 0.62522415 0.62402869 0.6180514  0.61685595]\n",
      "cv_scores mean:0.6210791011275859\n",
      "\n",
      "Logistic =  solver :   sag  / max_iter :  50\n",
      "[0.62149254 0.62149254 0.62089552 0.61887694 0.62044232 0.62343096\n",
      " 0.62522415 0.62402869 0.6180514  0.61685595]\n",
      "cv_scores mean:0.6210791011275859\n",
      "\n",
      "Logistic =  solver :   sag  / max_iter :  100\n",
      "[0.62149254 0.62149254 0.62089552 0.61887694 0.62044232 0.62343096\n",
      " 0.62522415 0.62402869 0.6180514  0.61685595]\n",
      "cv_scores mean:0.6210791011275859\n",
      "\n",
      "Logistic =  solver :   sag  / max_iter :  200\n",
      "[0.62149254 0.62149254 0.62089552 0.61887694 0.62044232 0.62343096\n",
      " 0.62522415 0.62402869 0.6180514  0.61685595]\n",
      "cv_scores mean:0.6210791011275859\n",
      "\n",
      "SVM =  C :  0.1  / gamma :  0.1  / Kernel :  linear\n",
      "[0.62149254 0.62149254 0.62149254 0.62126643 0.62163778 0.62163778\n",
      " 0.62163778 0.62163778 0.62163778 0.62163778]\n",
      "cv_scores mean:0.6215570698355292\n",
      "\n",
      "SVM =  C :  0.1  / gamma :  10  / Kernel :  linear\n",
      "[0.62149254 0.62149254 0.62149254 0.62126643 0.62163778 0.62163778\n",
      " 0.62163778 0.62163778 0.62163778 0.62163778]\n",
      "cv_scores mean:0.6215570698355292\n",
      "\n",
      "SVM =  C :  0.1  / gamma :  100  / Kernel :  linear\n",
      "[0.62149254 0.62149254 0.62149254 0.62126643 0.62163778 0.62163778\n",
      " 0.62163778 0.62163778 0.62163778 0.62163778]\n",
      "cv_scores mean:0.6215570698355292\n",
      "\n",
      "SVM =  C :  0.1  / gamma :  0.1  / Kernel :  poly\n",
      "[0.62149254 0.62149254 0.62149254 0.62126643 0.62163778 0.62163778\n",
      " 0.62163778 0.62163778 0.62163778 0.62163778]\n",
      "cv_scores mean:0.6215570698355292\n",
      "\n",
      "SVM =  C :  0.1  / gamma :  10  / Kernel :  poly\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"bank-full.csv\", sep=';')\n",
    "\n",
    "# Data Preprocessing\n",
    "#1) Data Restructuring - table vertical decomposition\n",
    "# remove features do not affect on economy\n",
    "df.drop(['age', 'job', 'marital', 'contact', 'day', 'month', 'duration', \n",
    "         'campaign', 'pdays', 'previous', 'poutcome','y'], axis='columns', inplace=True)\n",
    "\n",
    "#plt.figure(figsize=(15, 15))\n",
    "df.hist(rwidth=0.8) # Dataset Distribution\n",
    "\n",
    "df = df.astype({\"balance\" : float}) # change 'balance' int into float\n",
    "# print(df.head(5))\n",
    "\n",
    "# 2) Data Restructuring - data value changes\n",
    "# cleaning data\n",
    "\n",
    "# missing data : 'unknown' -> NaN\n",
    "df = df.replace(\"unknown\", np.nan)\n",
    "\n",
    "print(\"- missing data before removal : \", len(df)),\n",
    "print(df.isnull().sum()) # check missing data\n",
    "df = df.dropna(axis=0) # drop NaN\n",
    "print(\"- missing data after removal : \", len(df)),\n",
    "print(df.isnull().sum()) # check missing data\n",
    "\n",
    "df = df.reset_index(drop=True) # reset index\n",
    "\n",
    "\n",
    "# Decrease the 'education' value to two.\n",
    "# primary + secondary -> compulsory education\n",
    "# tertiary -> non compulsory education\n",
    "df = df.replace(\"primary\", \"compulsory\")\n",
    "df = df.replace(\"secondary\", \"compulsory\")\n",
    "\n",
    "print(df.head(10))\n",
    "\n",
    "\n",
    "# remove Redundancy\n",
    "print(\"- data before removing redundancy : \", len(df))\n",
    "df = df.drop_duplicates()\n",
    "print(\"- data after removing redundancy : \", len(df))\n",
    "\n",
    "#print(df.heasd(20))\n",
    "\n",
    "\n",
    "# Feature Engineering\n",
    "# Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelEncoder = LabelEncoder()\n",
    "\n",
    "labelEncoder.fit(df['education'])\n",
    "df['education'] = labelEncoder.transform(df['education'])\n",
    "labelEncoder.fit(df['default'])\n",
    "df['default'] = labelEncoder.transform(df['default'])\n",
    "labelEncoder.fit(df['housing'])\n",
    "df['housing'] = labelEncoder.transform(df['housing'])\n",
    "labelEncoder.fit(df['loan'])\n",
    "df['loan'] = labelEncoder.transform(df['loan'])\n",
    "\n",
    "print(df)\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "plt.boxplot(df['balance'])\n",
    "plt.show()\n",
    "\n",
    "df['balance'].quantile([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1])\n",
    "\n",
    "\n",
    "# Outlier\n",
    "print(len(df[df['balance']>50000]))\n",
    "print(len(df[df['balance']<-1000]))\n",
    "\n",
    "print(\"- data before removing outlier : \", len(df))\n",
    "df = df[df['balance']<=50000]\n",
    "df = df[df['balance']>=-1000]\n",
    "print(\"- data after removing outlier : \", len(df))\n",
    "\n",
    "\n",
    "#classifier attribute to target\n",
    "X = df.drop(['education'],axis = 1)\n",
    "y = df['education'].values\n",
    "\n",
    "\n",
    "#scaler\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "print(X)\n",
    "\n",
    "\n",
    "# Feature Engineering - Feature Reduction(PCA)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_ = StandardScaler().fit_transform(X)\n",
    "pca = PCA(n_components=4)\n",
    "pc = pca.fit_transform(X_)\n",
    "print(pc)\n",
    "\n",
    "\n",
    "#Calculation kfold's accuracy\n",
    "def cal(model):\n",
    "    cv_scores = cross_val_score(model, X, y, cv=10)\n",
    "    print(cv_scores)\n",
    "    print('cv_scores mean:{}'.format(np.mean(cv_scores)))\n",
    "    print()\n",
    "\n",
    "Dscore = None\n",
    "Dmodel = None\n",
    "\n",
    "\n",
    "#Pick Decision Tree's max model\n",
    "def update(model): \n",
    "    global Dmodel, Dscore\n",
    "    cv_scores = cross_val_score(model, X, y, cv=10)\n",
    "    n_score = np.mean(cv_scores)\n",
    "    if (Dscore == None):\n",
    "        Dscore = n_score\n",
    "        Dmodel = model\n",
    "    elif(n_score > Dscore):\n",
    "        Dscore = n_score\n",
    "        Dmodel = model\n",
    "\n",
    "Cscore = None\n",
    "Cmodel = None\n",
    "\n",
    "#DecstionTree's all case\n",
    "for case in['gini', 'entropy']:\n",
    "    print(\"DecisionTree = \" , case)\n",
    "    model = DecisionTreeClassifier(criterion = case, max_depth=3, random_state=0)\n",
    "    cal(model)\n",
    "    update(model)\n",
    "\n",
    "\n",
    "#Pick Logistic Regression's max model\n",
    "def update2(model):\n",
    "    global Cmodel, Cscore\n",
    "    cv_scores = cross_val_score(model, X, y, cv=10)\n",
    "    n_score = np.mean(cv_scores)\n",
    "    if (Cscore == None):\n",
    "        Cscore = n_score\n",
    "        Cmodel = model\n",
    "    elif(n_score > Cscore):\n",
    "        Cscore = n_score\n",
    "        Cmodel = model\n",
    "\n",
    "Sscore = None\n",
    "Smodel = None\n",
    "\n",
    "#Logistic Regression's all case\n",
    "for case in['liblinear', 'lbfgs', 'sag']:\n",
    "    for max in [50, 100,200]:\n",
    "        print(\"Logistic = \" , \"solver :  \" , case , \" / max_iter : \" , max)\n",
    "        model = LogisticRegression(solver = case, max_iter = max)\n",
    "        cal(model)\n",
    "        update2(model)\n",
    "\n",
    "\n",
    "#Pick SVM's max model\n",
    "def update3(model):\n",
    "    global Smodel, Sscore\n",
    "    cv_scores = cross_val_score(model, X, y, cv=10)\n",
    "    n_score = np.mean(cv_scores)\n",
    "    if (Sscore == None):\n",
    "        Sscore = n_score\n",
    "        Smodel = model\n",
    "    elif(n_score > Sscore):\n",
    "        Sscore = n_score\n",
    "        Smodel = model\n",
    "\n",
    "#SVM's all case\n",
    "for case in[0.1, 1.0, 10.0]:\n",
    "    for kernel in['linear', 'poly',  'rbf', 'sigmoid']:\n",
    "        for gam in[0.1, 10, 100]:\n",
    "            print(\"SVM = \" , \"C : \" , case , \" / gamma : \" , gam , \n",
    "                  \" / Kernel : \" , kernel)\n",
    "            model = SVC(C = case, gamma = gam, kernel = kernel)\n",
    "            cal(model)\n",
    "            update3(model)\n",
    "\n",
    "\n",
    "#Training max model\n",
    "Dmodel = Dmodel.fit(X, y)\n",
    "Cmodel = Cmodel.fit(X, y)\n",
    "Smodel = Smodel.fit(X, y)\n",
    "\n",
    "#Decision Tree's confusion matrix\n",
    "confusion_matrix = pd.crosstab(y, Dmodel.predict(X), rownames=['Actual'], colnames=['Predicted'], margins= True)\n",
    "sn.heatmap(confusion_matrix, annot=True, fmt = 'd')\n",
    "plt.show()\n",
    "\n",
    "#Logistic Regression's confusion matrix\n",
    "confusion_matrix = pd.crosstab(y, Cmodel.predict(X), rownames=['Actual'], colnames=['Predicted'], margins= True)\n",
    "sn.heatmap(confusion_matrix, annot=True, fmt = 'd')\n",
    "plt.show()\n",
    "\n",
    "#SVN's confusion matrix\n",
    "confusion_matrix = pd.crosstab(y, Smodel.predict(X), rownames=['Actual'], colnames=['Predicted'], margins= True)\n",
    "sn.heatmap(confusion_matrix, annot=True, fmt = 'd')\n",
    "plt.show()\n",
    "\n",
    "#Box Plot\n",
    "x = ['Decision', 'Logistic', 'SVM']\n",
    "y = [Dscore, Cscore, Sscore]\n",
    "df = pd.DataFrame(dict(x=x, y=y))\n",
    "sn.factorplot(\"x\",\"y\", data=df,kind=\"bar\",size=6,aspect=2,legend_out=False)\n",
    "plt.ylim(0.7,1)\n",
    "plt.show()\n",
    "\n",
    "# chi squre\n",
    "x_0,x_1=[7084,1899],[7684,2439]\n",
    "x_dataframe=pd.DataFrame([x_0,x_1],columns=['loan_0','loan_1'],index=['housing_0','housing_1'])\n",
    "print(x_dataframe)\n",
    "from scipy.stats import chisquare\n",
    "result=chisquare(x_0,f_exp=x_1)\n",
    "print(result)\n",
    "\n",
    "x_0,x_1=[1828,3920,3235],[2074,4950,3099]\n",
    "x_dataframe=pd.DataFrame([x_0,x_1],columns=['Education_0','Education_1','Edcuation_2'],index=['housing_0','housing_1'])\n",
    "print(x_dataframe)\n",
    "from scipy.stats import chisquare\n",
    "result=chisquare(x_0,f_exp=x_1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
